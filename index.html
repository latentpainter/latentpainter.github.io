<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1"> 
<title>Latent Painter</title>

<meta property="og:title" content="Latent Painter"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Turning diffuser predictions into painting actions"/>
<meta property="og:image" content="https://latentpainter.github.io/assets/img/android-chrome-192x192.png"/>

<link rel="stylesheet" href="./assets/css/bulma.min.css">
<link rel="stylesheet" href="./assets/css/bulma-carousel.min.css">
<link rel="stylesheet" href="./assets/css/bulma-slider.min.css">
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.2/css/bootstrap.min.css" rel="stylesheet">
<link href="./assets/css/style.css" rel="stylesheet">


<link rel="icon" href="./assets/img/favicon.ico">

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="./assets/js/bulma-carousel.min.js"></script>
<script src="./assets/js/bulma-slider.min.js"></script>
<script src="./assets/js/bulma-init.js"></script>


</head>

<body>
<div class="container-fluid my-md-5">
<div class="content">
<div class="row py-3">
  <h1><strong>Latent Painter</strong></h1>
  <p id="authors" class="py-1">
    <a href="https://www.linkedin.com/in/jessysu/">Shih-Chieh Su</a>
  </p>
  <div class="container">
    <div id="teaser-carousel" class="carousel teaser-carousel">
      <div class="item">
        <video src="./assets/mp4/Paint Giza Pyramid by Rembrandt(33) Stroke24 20fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint Golden Gate by Monet(48) Stroke24 24fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint Opera House in Starry Night fade8 8fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint Colosseum by Rembrandt dissolve16v0.3_0.1 28fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/GF3 Suggested2 Stroke24 12fps 63s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/pingpong SD2GF17 fade8r 531 18fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/img2img radgrow 12fps.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Astronaut strok24 56fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Astronaut zigzag16 36fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint White Eiffel Tower by Monet stroke24 30fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint White Opera House in Starry Night stroke24 22fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
      <div class="item">
        <video src="./assets/mp4/Paint Forbidden City in Starry Night stroke24 24fps 20s.mp4" autoplay controls muted loop playsinline></video>
      </div>
    </div>
  </div>
  <h3 class="text-center"><em>Turning diffuser predictions into painting actions*</em></h3>
  <div class="d-md-flex justify-content-evenly mt-3">
    <a class="h4 text-secondary link-invalid">Code</a>
    <a class="h4" href="https://arxiv.org/abs/2308.16490">Paper</a>
    <a class="h4" href="#ref-block">References</a>
    <a class="h4" href="https://youtu.be/i0PuoyrjGlc">Video</a>
  </div>
  <p class="small mt-3">
    *Refrain from using generated arts where prohibits
  </p>
</div>
</div>

<div class="content">
<div class="row">
  <h2 class="text-center">Abstract</h2>
  <p>
    Latent diffuser models gain a lot of traction in generative AI for their efficiency, content diversity, and reasonable footprint.
    This work presents Latent Painter, which uses the latent as the canvas, and the diffuser predictions as the plan, to generate painting animation.
    In addition to composing the final output from blank, Latent Painter can transit one image to another, providing additional options to the existing interpolation-based method.
    Moreover, it can transit the generated images from two different sets of checkpoints.
  </p>
</div>
</div>

<div class="content">
<div class="row">
  <h2>Background</h2>
  <p>
    The latent diffuser predicts better and better final outputs along denoising process, which can be used as animation frames.
    However, the majority of the update is completed during the first few frames -- making the rest of the animation stall (Vid. 1).
    In a different scenario, animation transits between two generated images via interpolating both the embedded prompts and seeded latents (Vid. 2).
    While the image-to-image animation provides high quality morphology, it also comes with occasional disruptions and nonsense.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/astronaut diffuse 2fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div>Vid. 1</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/img2img 100slices slerp.mp4" autoplay controls muted loop playsinline></video>
    <div>Vid. 2</div>
  </div>
  </div>
</div>
</div>

<div class="content">
<div class="row d-flex align-items-start">
  <h2>Approach</h2>
  <p class="col-12 col-md-6 col-xl-4">
    Latent Painter schedules the painting actions on U-Net output of the latent diffuser.
    Among the latent channels, the channel with highest information gain is selected as the painting channel.
    Within the painting channel, each move motivates the painter to stroke at the location of highest information gain.
    Once placed, the diffuser prediction passes through the stroke location onto the canvas.
    However, restrictions including stroke size, allowed channels, allowed stroke count, and accumulated motivation prevent the output being updated fully as intended.
    The residual is rolled into the next schedule until the last, which guarantees the final state (Fig. 1).
  </p>
  <div class="col-12 col-md-6 col-xl-8 text-center">
    <img class="img-fluid" src="./assets/img/PainterPipe.PNG"></img>
    <div>Fig. 1</div>
  </div>
  <p class="col-12 col-md-6 col-xl-12">
    In addition to paints, Latent Painter can also paint photos, or anything generated by latent diffusers. 
    The denoising nature of the U-Net guides the painting process from rough to detail.
    The stroke placement indicates the location in the current channel needing update the most, which typically is not evenly distributed in space (Vid. 3).
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Pair Stroke24 24fps 41s paint.mp4" autoplay controls muted loop playsinline></video>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Pair Stroke24 24fps 41s map.mp4" autoplay controls muted loop playsinline></video>
  </div>
  </div>
  <div class="text-center">Vid. 3: Latent Painter and stroke map</div>
</div>
</div>

<div class="content">
<div class="row">
  <h2>Beyond Strokes</h2>
  <p>
    Latent Painter allows non-stroking actions in between the schedules, with or without information flow constraints.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Paint Colosseum by Rembrandt dissolve16v0.3_0.1 28fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(a) Dissolve</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Paint Mt Rushmore in Starry Night radgrow 12fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(b) Glow</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/GF3 Suggested17 fade8 10fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(c) Fade</div>
  </div>
  </div>
  <div class="text-center">Vid. 4: Extensions from the Latent Painter strokes</div>
</div>
</div>


<div class="content">
<div class="row">
  <h2>Image Transition</h2>
  <p>
    When transitioning between images generated by the latent diffuser, the information flow runs the source image denoising schedule backward, and then the destination schedule forward.
    Through the constraints of the flow, the transition time can be traded with the detail.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/img2img radgrow 12fps.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(a) Glow</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/img2img zigzag16 32fps 19s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(b) Flip</div>
  </div>
  </div>
  <div class="text-center mb-3">Vid. 5: Latent Painter animates Vid. 2</div>
  <p>
    When the source and destination images share a certain part of background, such as in image editing, the interpolated latents between the source latent and the destination latent can be used as the prediction guidance.
    This provides crispy frames by avoiding the guidance from during denoising.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/im2im SEGA Cat Stroke 40fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(a)</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/im2im SEGA Street Stroke 40fps 20s C.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(b)</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/im2im SEGA Castle Rad 15fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(c)</div>
  </div>
  </div>
  <div class="text-center mb-3">Vid. 6: Semantically edited[3] lantents being painted with strokes (a)(b) and glow (c)</div>
  <p>
    With same VAE to interpret the latent, Latent Painter can transit source image to destination images that come from two different sets of the diffuser denoising checkpoints.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/pingpong SD2GF17 fade8r 531 18fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(a)</div>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/pingpong SD2GF2 fade8r 531 20fps 20s.mp4" autoplay controls muted loop playsinline></video>
    <div class="text-center">(b)</div>
  </div>
  </div>
  <div class="text-center">Vid. 7: Faded inter-checkpoint pingpongs</div>
</div>
</div>

<div class="content">
<div class="row">
  <h2>White Canvas</h2>
  <p>
    The VAE in diffusion system cannot decode the all-zero latent into a white image.
    With proper masking on the decoded image, Latent Painter can start from a white canvas.
  </p>
  <div class="d-md-flex justify-content-evenly">
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Paint White Opera House by Rembrandt(0!) Stroke24 26fps 20s.mp4" autoplay controls muted loop playsinline></video>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Paint White Opera House by Monet(40) Stroke24 25fps 20s.mp4" autoplay controls muted loop playsinline></video>
  </div>
  <div class="col-12 col-md-4 col-lg-3 text-center">
    <video class="img-fluid" src="./assets/mp4/Paint White Eiffel Tower by Monet stroke24 30fps 20s.mp4" autoplay controls muted loop playsinline></video>
  </div>
  </div>
  <div class="text-center">Vid. 8: Painting on white canvas</div>
</div>
</div>

<div class="content">
<div class="row">
  <h2 id="ref-block">References</h2>
  <ol>
    <li>
      Stable Diffusion [<a href="https://arxiv.org/abs/2112.10752">pdf</a>]
    </li>
    <li>
      CPIA: Channel Painter in Action [<a href="https://arxiv.org/pdf/1908.04694.pdf">pdf</a>].
      Compared to the Latent Painter, a generator layer of GAN has more channels to paint on [<a href="https://github.com/jessysu/cpia">demo</a>]. However, the action scheduling via segmentation is far less efficient than the diffusion predictions.
    </li>
    <li>
      SEGA: Instructing Diffusion using Semantic Dimensions [<a href="https://arxiv.org/abs/2301.12247">pdf</a>]
    </li>
  </ol>
</div>
</div>

<div class="content">
<div class="row">
  <h2>Bibtex</h2>
  <pre><code>@misc{su2023latent,
      title={Latent Painter}, 
      author={Shih-Chieh Su},
      year={2023},
      eprint={2308.16490},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
  </code></pre>
</div>
</div>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.1.3/js/bootstrap.min.js"></script>

</body>
</html>
